{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Base_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyotiRawat29/MastersThesis/blob/main/Base_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "708d3ce9"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as f\n",
        "from torch import nn\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from multiprocessing import cpu_count\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tensorflow import summary\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "708d3ce9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOB_9KVr_slm"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "id": "NOB_9KVr_slm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dvm8m425U-w",
        "outputId": "aee2dfe5-c7c6-422d-e2ae-89276200f245"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "2dvm8m425U-w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fc9674b"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "#load the ECG file\n",
        "src_dataset = sio.loadmat('/content/drive/MyDrive/ECG2(withDA).mat')\n",
        "#load the labels\n",
        "label=pd.read_csv('/content/drive/MyDrive/label.csv',header=None)"
      ],
      "id": "2fc9674b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9eaa823"
      },
      "source": [
        "testdata = src_dataset['ECG'] # use the key for data here\n",
        "X=testdata['Data'] #loading data"
      ],
      "id": "c9eaa823",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9da3d9ad"
      },
      "source": [
        "X=np.array(X[0])\n",
        "X = np.vstack(X[:,]).astype(np.float)\n",
        "X=torch.from_numpy(X)"
      ],
      "id": "9da3d9ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42e1f46a"
      },
      "source": [
        "label=np.array(label, dtype=object) # loading labels \n",
        "label=np.array(label)\n",
        "label= np.vstack(label[:,]).astype(np.float)\n",
        "Y = torch.tensor(label)"
      ],
      "id": "42e1f46a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bce4972",
        "outputId": "84c6f178-0dc2-4c23-a042-58ac7c46bd3c"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "id": "5bce4972",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1273, 4000])\n",
            "torch.Size([1273, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ae1486"
      },
      "source": [
        "def create_datasets(X, y, test_size=0.2, time_dim_first=False):\n",
        "    enc = LabelEncoder()\n",
        "    y_enc = enc.fit_transform(y)\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, stratify=Y)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=1)  \n",
        "    print(X_train.shape)\n",
        "    print(X_valid.shape)\n",
        "    print(y_train.shape)\n",
        "    y_train=torch.squeeze(y_train)\n",
        "    print(y_test.shape)\n",
        "    y_valid=torch.squeeze(y_valid)\n",
        "    y_test=torch.squeeze(y_test)\n",
        "\n",
        "    X_train, X_valid, X_test = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train, X_valid,X_test)]\n",
        "    y_train, y_valid,y_test = [torch.tensor(arr, dtype=torch.long) for arr in (y_train, y_valid,X_test)]\n",
        "    print(X_train.shape)\n",
        "    print(X_valid.shape)\n",
        "    print(X_test.shape)\n",
        "    train_ds = TensorDataset(X_train, y_train)\n",
        "    valid_ds = TensorDataset(X_valid, y_valid)\n",
        "    tst_ds=TensorDataset(X_test,y_test)\n",
        "    return train_ds, valid_ds,tst_ds, enc"
      ],
      "id": "03ae1486",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81b69bb5",
        "outputId": "fef734f4-72e3-4b75-d88f-be9d7b85a70d"
      },
      "source": [
        "trn_ds, val_ds, tst_data, enc = create_datasets(X, Y)"
      ],
      "id": "81b69bb5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([763, 4000])\n",
            "torch.Size([255, 4000])\n",
            "torch.Size([763, 1])\n",
            "torch.Size([255, 1])\n",
            "torch.Size([763, 4000])\n",
            "torch.Size([255, 4000])\n",
            "torch.Size([255, 4000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe229683"
      },
      "source": [
        "def create_loaders(train_ds, valid_ds,tst_ds, bs=512, jobs=0):\n",
        "    train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=jobs)\n",
        "    valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=jobs)\n",
        "    tst_dl = DataLoader(tst_ds, bs, shuffle=False, num_workers=jobs)\n",
        "    return train_dl, valid_dl,tst_ds"
      ],
      "id": "fe229683",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1531e0f2"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size,batch_first=True)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "\n",
        "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
        "                            torch.zeros(1,1,self.hidden_layer_size))\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        h0 = torch.zeros(1, input_seq.size(0), self.hidden_layer_size).to(device) \n",
        "        c0 = torch.zeros(1, input_seq.size(0), self.hidden_layer_size).to(device)\n",
        "        lstm_out, _ = self.lstm(input_seq, (h0,c0))\n",
        "        lstm_out = self.fc(lstm_out[:, -1, :])\n",
        "        #predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
        "        #print(\"predictions\",predictions)\n",
        "        return lstm_out\n",
        "\n",
        "    def init_hidden(self, x):\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        \n",
        "        #print('hidden layer')\n",
        "        #print(h0.shape)\n",
        "        #print(x.size(0))\n",
        "        #print(layer_dim)\n",
        "        return [t.to(device) for t in (h0, c0)]"
      ],
      "id": "1531e0f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa7f84af",
        "outputId": "7d75ce9e-6013-4e72-d689-fb99e9ef844a"
      },
      "source": [
        "trn_ds, val_ds, tst_data, enc = create_datasets(X, Y)\n",
        "bs =50\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "id": "aa7f84af",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([763, 4000])\n",
            "torch.Size([255, 4000])\n",
            "torch.Size([763, 1])\n",
            "torch.Size([255, 1])\n",
            "torch.Size([763, 4000])\n",
            "torch.Size([255, 4000])\n",
            "torch.Size([255, 4000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "195b675f",
        "outputId": "cb017c2e-c9dc-4d4d-ad29-1c3bb9302ee2"
      },
      "source": [
        "print(f'Creating data loaders with batch size: {bs}')\n",
        "trn_dl, val_dl,tst_data = create_loaders(trn_ds, val_ds,tst_data, bs, jobs=cpu_count())\n",
        "model = LSTM(1,500,1)\n",
        "layer_dim = 1"
      ],
      "id": "195b675f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating data loaders with batch size: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X43UV_mmgd0",
        "outputId": "c8cbd195-e19d-43e1-e7f4-26e430103ddb"
      },
      "source": [
        "!pip install torchinfo"
      ],
      "id": "9X43UV_mmgd0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.5.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrSlAar7mVmJ"
      },
      "source": [
        "from tensorflow import summary\n",
        "from torchinfo import summary"
      ],
      "id": "RrSlAar7mVmJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jai2350ymjab",
        "outputId": "3fd2c5ef-ef85-48b2-8711-ba3d1f61dd52"
      },
      "source": [
        "summary(model)"
      ],
      "id": "jai2350ymjab",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "LSTM                                     --\n",
              "├─LSTM: 1-1                              1,006,000\n",
              "├─Linear: 1-2                            501\n",
              "├─Linear: 1-3                            501\n",
              "=================================================================\n",
              "Total params: 1,007,002\n",
              "Trainable params: 1,007,002\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "364294e7"
      },
      "source": [
        "model = model.to(device)"
      ],
      "id": "364294e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2700089b"
      },
      "source": [
        "seq_dim = 4000\n",
        "lr = 0.001\n",
        "n_epochs = 101\n",
        "iterations_per_epoch = len(trn_dl)\n",
        "best_acc = 0\n",
        "patience, trials = 100, 0\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "layer_dim = 1\n",
        "output_dim = 3"
      ],
      "id": "2700089b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4645b7f6"
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "id": "4645b7f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3caMjzCn2WyJ"
      },
      "source": [
        "import copy"
      ],
      "id": "3caMjzCn2WyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN97Rmc6A7lE"
      },
      "source": [
        "best_loss = 1\n",
        "n_epochs = 100\n",
        "best_model_wts = copy.deepcopy(model.state_dict())"
      ],
      "id": "RN97Rmc6A7lE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCP2xbqMzkAG"
      },
      "source": [
        "history = dict(train =[], val = [])"
      ],
      "id": "DCP2xbqMzkAG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "ea56dce6",
        "outputId": "c665e47d-df18-4d78-e3c5-fb142a5eeaf5"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  #training loop\n",
        "  for i, (x_batch, y_batch) in enumerate(trn_dl):\n",
        "        model.to(device)\n",
        "        model.train()\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        x_batch=torch.unsqueeze(x_batch,2)\n",
        "\n",
        "        \n",
        "        out = model(x_batch)\n",
        "        y_batch=torch.unsqueeze(y_batch,0)\n",
        "        y_batch = y_batch.to(torch.float32)\n",
        "\n",
        "        out = out.to(torch.float32)\n",
        "        out=torch.transpose(out,1,0)\n",
        "        loss = loss_function(out, torch.max(y_batch, 1)[1])\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        train_losses.append(loss.item())\n",
        " \n",
        "\n",
        "  correct, total = 0, 0\n",
        "  #validation loop\n",
        "  for x_val, y_val in val_dl:\n",
        "        model.eval()\n",
        "        x_val, y_val = [t for t in (x_val, y_val)]\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        x_val=torch.unsqueeze(x_val,2)\n",
        "\n",
        "        out = model(x_val)\n",
        "        y_val=torch.unsqueeze(y_val,0)\n",
        "        y_val = y_val.to(torch.float32)\n",
        "\n",
        "        out = out.to(torch.float32)\n",
        "        out=torch.transpose(out,1,0)\n",
        "        loss = loss_function(out, torch.max(y_val, 1)[1])\n",
        "        val_losses.append(loss.item())\n",
        "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
        "        print(\"y_valsize\",y_val.size(0))\n",
        "        print(\"y_valsize\",y_val.size(1))\n",
        "        total += y_val.size(0)\n",
        "        print('total',total)\n",
        "        correct += (preds == y_val).sum().item()\n",
        "        print('correct',correct)\n",
        "\n",
        "  \n",
        "  train_loss = np.mean(train_losses)\n",
        "\n",
        "  val_loss = np.mean(val_losses)\n",
        "\n",
        "  history['train'].append(train_loss)\n",
        "  history['val'].append(val_loss)\n",
        "  print(\"correct\",correct)\n",
        "  print(\"total\",total)\n",
        "\n",
        "  acc = correct / total\n",
        "\n",
        "  #if epoch % 5 == 0:\n",
        "  print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
        "\n",
        "  #if acc > best_acc:\n",
        "   #     trials = 0\n",
        "    #    best_acc = acc\n",
        "     #   torch.save(model.state_dict(), 'best.pth')\n",
        "      #  print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
        "  #else:\n",
        "   #     trials += 1\n",
        "    #    if trials >= patience:\n",
        "     #       print(f'Early stopping on epoch {epoch}')\n",
        "      #      break\n",
        "#writer.flush()\n",
        "#writer.add_graph(model,x_batch)\n",
        "#writer.close()"
      ],
      "id": "ea56dce6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_valsize 1\n",
            "y_valsize 50\n",
            "total 1\n",
            "correct 0\n",
            "y_valsize 1\n",
            "y_valsize 50\n",
            "total 2\n",
            "correct 0\n",
            "y_valsize 1\n",
            "y_valsize 50\n",
            "total 3\n",
            "correct 0\n",
            "y_valsize 1\n",
            "y_valsize 50\n",
            "total 4\n",
            "correct 0\n",
            "y_valsize 1\n",
            "y_valsize 50\n",
            "total 5\n",
            "correct 13\n",
            "y_valsize 1\n",
            "y_valsize 5\n",
            "total 6\n",
            "correct 14\n",
            "correct 14\n",
            "total 6\n",
            "Epoch:   1. Loss: 1.6160. Acc.: 233.33%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-85cf4ddfb51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1f73d36"
      },
      "source": [
        "test_dl = DataLoader(tst_data, batch_size=64, shuffle=False)\n",
        "test = []\n",
        "for batch, _ in tst_data:\n",
        "    batch=batch.to(device)\n",
        "    batch = batch.reshape(1,4000,1)\n",
        "    out = model.train()(batch)\n",
        "    y_hat = F.log_softmax(out, dim=1).argmax(dim=1)\n",
        "    test += y_hat.tolist()"
      ],
      "id": "b1f73d36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jo-8J5mzDrs"
      },
      "source": [
        "ax = plt.figure().gca()\n",
        "\n",
        "ax.plot(history['train'])\n",
        "ax.plot(history['val'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.title('Loss over epochs')\n",
        "#plt.show()\n",
        "plt.savefig('Loss_over_epochs.png')"
      ],
      "id": "1jo-8J5mzDrs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwpLX4QSlOxu"
      },
      "source": [
        ""
      ],
      "id": "cwpLX4QSlOxu",
      "execution_count": null,
      "outputs": []
    }
  ]
}