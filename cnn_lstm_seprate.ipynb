{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn lstm seprate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMr3nTiFMLwvUzWApyeOSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyotiRawat29/MastersThesis/blob/main/cnn_lstm_seprate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d2wXQ0KwIxD"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as f\n",
        "from torch import nn\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from multiprocessing import cpu_count\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8omIUJZtwPZm"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "251cBXyzwSvL"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqSpSDVewVgg",
        "outputId": "a7659613-e567-4c6e-9253-9193ff9295f8"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIkwqmvPwbd6"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "#load the ECG file\n",
        "src_dataset = sio.loadmat('/content/drive/MyDrive/ECG2(withDA).mat')\n",
        "#load the labels\n",
        "label=pd.read_csv('/content/drive/MyDrive/label.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLiy4lOnwk36"
      },
      "source": [
        "#print(src_dataset)\n",
        "testdata = src_dataset['ECG'] # use the key for data here\n",
        "X=testdata['Data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gso02ufxTNc3",
        "outputId": "308d5be4-4370-4a2b-8390-f347fd23210f"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[array([[ 0.01601611,  0.01644181,  0.01690118, ...,  0.00294596,\n",
              "         0.00106469, -0.00456328],\n",
              "       [-0.11488888, -0.12236424, -0.12891141, ..., -0.03361464,\n",
              "        -0.03650065, -0.03900078],\n",
              "       [-0.04865461, -0.06793926, -0.0696586 , ..., -0.30155847,\n",
              "        -0.33376829, -0.34922594],\n",
              "       ...,\n",
              "       [ 0.11534132,  0.10149052,  0.08043098, ..., -0.12040478,\n",
              "        -0.10044553, -0.07588876],\n",
              "       [-0.04609605, -0.03321084, -0.01958534, ..., -0.01756399,\n",
              "        -0.01391065, -0.01017211],\n",
              "       [ 0.03929655,  0.01265927, -0.00714671, ...,  0.02241839,\n",
              "         0.03816335,  0.05258733]])]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo81IchJwnD8"
      },
      "source": [
        "X=np.array(X[0])\n",
        "X = np.vstack(X[:,]).astype(np.float)\n",
        "X=torch.from_numpy(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bOtSPU7wvJ4"
      },
      "source": [
        "label=np.array(label, dtype=object)\n",
        "label=np.array(label)\n",
        "label= np.vstack(label[:,]).astype(np.float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_UD8T4Pl5GU",
        "outputId": "8d4f9154-462c-445a-d027-1b816d63d031"
      },
      "source": [
        "enc = LabelEncoder()\n",
        "Y_enc = enc.fit_transform(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn6VlMltl12b"
      },
      "source": [
        " Y = torch.tensor(Y_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kdm40MiE06s"
      },
      "source": [
        "torch.set_printoptions(threshold=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrnWsDiwwwIy"
      },
      "source": [
        "def create_datasets(X, Y):\n",
        "    enc = LabelEncoder()\n",
        "    Y_enc = enc.fit_transform(Y)\n",
        "    print(\"len of X and Y is\",X.shape,Y.shape)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify = Y) \n",
        "    X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.25, stratify = Y_train) \n",
        "    #squeeze labelled data to make it 1 dimension array\n",
        "    Y_train=torch.squeeze(Y_train)\n",
        "    Y_valid=torch.squeeze(Y_valid)\n",
        "    Y_test=torch.squeeze(Y_test)\n",
        "    print(\"X_train, X_valid, X_test shape before list comprehension\",X_train.shape, X_valid.shape, X_test.shape)\n",
        "    print(\"X_train, X_valid, X_test dtype before list comprehension\",X_train.dtype, X_valid.dtype, X_test.dtype)\n",
        "    print(\"Y_train, Y_valid, Y_test dtype before list comprehension\",Y_train.dtype, Y_valid.dtype, Y_test.dtype)\n",
        "    #the tensors created have dtype float64 but the models have dtypes float32 and its easier to change dtypes of the tensors instead of a model\n",
        "    X_train, X_valid, X_test = [torch.tensor(arr, dtype=torch.float32) for arr in (X_train, X_valid,X_test)]\n",
        "    Y_train, Y_valid,Y_test = [torch.tensor(arr, dtype=torch.long) for arr in (Y_train, Y_valid,Y_test)]\n",
        "    print(\"X_train, X_valid, X_test shape after list comprehension\",X_train.shape, X_valid.shape, X_test.shape)\n",
        "    print(\"X_train, X_valid, X_test dtype before list comprehension\",X_train.dtype, X_valid.dtype, X_test.dtype)\n",
        "    print(\"Y_train, Y_valid, Y_test dtype before list comprehension\",Y_train.dtype, Y_valid.dtype, Y_test.dtype)\n",
        "    #convert training and testing data into Tensor Dataset\n",
        "    train_ds = TensorDataset(X_train, Y_train)\n",
        "    valid_ds = TensorDataset(X_valid, Y_valid)\n",
        "    test_ds = TensorDataset(X_test,Y_test)\n",
        "    print(\"train_ds, valid_ds, test_ds length of datasets respectively\",len(train_ds), len(valid_ds), len(test_ds))\n",
        "    return train_ds, valid_ds,test_ds, enc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7icMunAiw5an"
      },
      "source": [
        "def create_loaders(train_ds, valid_ds,test_ds, bs, jobs=0):\n",
        "    train_dl = DataLoader(train_ds, bs, shuffle=True, num_workers=jobs)\n",
        "    valid_dl = DataLoader(valid_ds, bs, shuffle=True, num_workers=jobs)\n",
        "    test_dl = DataLoader(test_ds, bs, shuffle=True, num_workers=jobs)\n",
        "    print(\"lenth of data loaders train_dl, valid_dl, test_dl\",len(train_dl), len(valid_dl), len(test_dl))\n",
        "    return train_dl, valid_dl, test_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt-Ce_Ahw7Tj"
      },
      "source": [
        "def accuracy(output, target):\n",
        "    return (output.argmax(dim=1) == target).float().mean().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcAmUzoSDIHu"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, input_dim,output_channels, kernel_size, stride=1):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_channels = output_channels\n",
        "    self.cnn = nn.Conv1d(input_dim,output_channels, kernel_size=1)\n",
        "    self.fc = nn.Linear(hidden_dim, output_cnn)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.cnn(x)\n",
        "    print(\"output shape before fc\",out.size)\n",
        "    out = self.fc(out[:,-1:])\n",
        "    print(\"shape of output\", out.size())\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvAflK_W-Ri7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "2f33fd52-b0fd-4a87-b0c8-56e629824d52"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, output_cnn, hidden_dim_lstm, layer_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.output_cnn = output_cnn\n",
        "    self.hidden_dim_lstm = hidden_dim_lstm\n",
        "    self.layer_dim = layer_dim\n",
        "    self.lstm = nn.LSTM(output_cnn, hidden_dim_lstm, layer_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim_lstm, output_dim)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    h0, c0 = self.init_hidden(x)\n",
        "    out, (hn, cn) = self.lstm(x, (h0,c0))\n",
        "    print(f'shape of out before fc_LSTM is {out.size()}')\n",
        "    out = self.fc(out[:,-1, :])\n",
        "    print(f'shape of out after fc_LSTM is {out.size()}')\n",
        "    print(f'final output is {out} ')\n",
        "    return out\n",
        "  \n",
        "  def init_hidden(self, x):\n",
        "    h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim_lstm)\n",
        "    c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim_lstm)\n",
        "    #print(\"h0 size in init function\",h0.size())\n",
        "    return [t.to(device) for t in (h0, c0)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6d6d31dcc6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_cnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_dim_lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiRZSzQbw9HD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "ebee10c6-1b58-430e-bcb3-237b15adf255"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim,output_channels=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "        self.cnn = nn.Conv1d(input_dim,output_channels, kernel_size=1)\n",
        "        self.fc = nn.Linear(hidden_dim, output_cnn)\n",
        "        self.lstm = nn.LSTM(output_cnn, hidden_dim, layer_dim, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "        self.batch_size = None\n",
        "        self.hidden = None\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h0, c0 = self.init_hidden(x)\n",
        "        out1 = self.cnn(x)\n",
        "        #print(\"output_cnn\",out1)\n",
        "        #print(\"output_cnn_size\",out1.size())\n",
        "        out2 = self.fc(out1[:,-1:])\n",
        "        #print(\"out_size fc_cnn\",out2.size())\n",
        "        #print(\"h0,c0 size\", h0.size(),c0.size())\n",
        "        out, (hn, cn) = self.lstm(out2, (h0, c0))\n",
        "        #print(\"output shape lstm\",out.size())\n",
        "        #output's dimension has been reduced\n",
        "        out = self.fc1(out[:, -1, :])\n",
        "        #print(\"output size fc_lstm\",out.size())\n",
        "        #print(\"final output\",out)\n",
        "        #out = self.softmax(out)\n",
        "        #print(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def init_hidden(self, x):\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        #print(\"h0 size in init function\",h0.size())\n",
        "        return [t.to(device) for t in (h0, c0)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c030ce43d30d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLSTMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RVmqpWtxDsY",
        "outputId": "8789d44c-81db-4311-dbc6-648436820950"
      },
      "source": [
        "train_ds, val_ds, test_data, enc = create_datasets(X, Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of X and Y is torch.Size([1273, 4000]) torch.Size([1273])\n",
            "X_train, X_valid, X_test shape before list comprehension torch.Size([763, 4000]) torch.Size([255, 4000]) torch.Size([255, 4000])\n",
            "X_train, X_valid, X_test dtype before list comprehension torch.float64 torch.float64 torch.float64\n",
            "Y_train, Y_valid, Y_test dtype before list comprehension torch.int64 torch.int64 torch.int64\n",
            "X_train, X_valid, X_test shape after list comprehension torch.Size([763, 4000]) torch.Size([255, 4000]) torch.Size([255, 4000])\n",
            "X_train, X_valid, X_test dtype before list comprehension torch.float32 torch.float32 torch.float32\n",
            "Y_train, Y_valid, Y_test dtype before list comprehension torch.int64 torch.int64 torch.int64\n",
            "train_ds, valid_ds, test_ds length of datasets respectively 763 255 255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TZ-t8wZGlbb",
        "outputId": "8e6f7e6d-3d83-45a2-b718-2648080073a4"
      },
      "source": [
        "bs = 32\n",
        "train_dl, valid_dl,test_data = create_loaders(train_ds, val_ds,test_data, bs, jobs=cpu_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenth of data loaders train_dl, valid_dl, test_dl 24 8 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgPJVfOxEOL"
      },
      "source": [
        "\n",
        "\n",
        "input_dim = 1\n",
        "hidden_dim = 4000\n",
        "output_cnn = 100\n",
        "layer_dim = 1\n",
        "output_dim = 3\n",
        "seq_dim = 4000\n",
        "lr = 0.001\n",
        "output_channels = 4000\n",
        "hidden_dim_lstm = 100\n",
        "\n",
        "n_epochs = 101\n",
        "iterations_per_epoch = len(train_dl)\n",
        "best_acc = 0\n",
        "patience, trials = 100, 0\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xpcivK_-tk_"
      },
      "source": [
        "model = CNN(input_dim, output_channels, kernel_size =1)\n",
        "model = model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoXW1kDkK-GN"
      },
      "source": [
        "model_lstm = LSTM(output_cnn,hidden_dim_lstm,layer_dim,output_dim)\n",
        "model_lstm = model_lstm.to(device)\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "z_DkanOYxKzB",
        "outputId": "77229f93-cff3-4d92-cc00-1a901353e4c0"
      },
      "source": [
        "model = LSTMClassifier(input_dim,hidden_dim,layer_dim,output_dim)\n",
        "model = model.to(device)\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-131e2aa8966f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LSTMClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3t2o-FBD18K",
        "outputId": "135090f4-dc2a-4a4f-b517-cb8a397a5716"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (cnn): Conv1d(1, 4000, kernel_size=(1,), stride=(1,))\n",
            "  (fc): Linear(in_features=4000, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lhbuabNMmlI"
      },
      "source": [
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUTecHiz_twP",
        "outputId": "65f5b1c0-7f1c-436e-8224-b29a70fefe9a"
      },
      "source": [
        "history = dict(train =[], val = [])\n",
        "best_loss = 1\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "for epochs in range(1, n_epochs+1):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  for x_batch,y_batch in train_dl:\n",
        "    print(f'training loop :: epoch is {epochs}')\n",
        "    model.train()\n",
        "    print(f'x_batch size is {x_batch.size()}')\n",
        "    x_batch = x_batch.unsqueeze(1)\n",
        "    optimizer.zero_grad()\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    features_cnn_x = model(x_batch)\n",
        "    feature_cnn_y = y_batch\n",
        "    features_cnn_x = features_cnn_x.to(device)\n",
        "    feature_cnn_y = feature_cnn_y.to(device)\n",
        "    model_lstm.train()\n",
        "    out = model_lstm(features_cnn_x)\n",
        "    loss = criteria(out,y_batch)\n",
        "    print(\"loss is \",loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x_val,y_val in valid_dl:\n",
        "      print(f'validation loop :: epoch is {epochs}')\n",
        "      model.eval()\n",
        "      x_val =x_val.unsqueeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      x_val = x_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "      features_cnn_val_x = model(x_val)\n",
        "      feature_cnn_val_y = y_val\n",
        "      features_cnn_val_x = features_cnn_val_x.to(device)\n",
        "      feature_cnn_val_y = feature_cnn_val_y.to(device)\n",
        "      model_lstm.eval()\n",
        "      out_val = model_lstm(features_cnn_val_x)\n",
        "      loss_val = criteria(out_val,y_val)\n",
        "      print(\"loss is (validation)\",loss_val)\n",
        "      val_losses.append(loss_val.item())\n",
        "          \n",
        "  train_loss = np.mean(train_losses)\n",
        "  val_loss = np.mean(val_losses)\n",
        "\n",
        "  history['train'].append(train_loss)\n",
        "  history['val'].append(val_loss)     \n",
        "  print(f'Epoch {epochs} : trainloss {train_loss} : val loss {val_loss}')\n",
        "        #writer.add_scalars('Training vs validation Loss',\n",
        "        #                   {'Training' : loss},\n",
        "          #                  epochs *len( history['train']))\n",
        "\n",
        "writer.flush()\n",
        "writer.add_graph(model,x_batch)\n",
        "writer.close()\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0627)\n",
            "validation loop :: epoch is 97\n",
            "output shape before fc torch.Size([31, 4000, 4000])\n",
            "shape of output torch.Size([31, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([31, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([31, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0900)\n",
            "Epoch 97 : trainloss 1.0750498473644257 : val loss 1.0761675387620926\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1155, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0796, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1113, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1165, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0891, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0722, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0933, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0501, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0174, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0807, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0944, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0448, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0986, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0311, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1018, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0406, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1208, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0765, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1028, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0722, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(0.9899, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0669, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0669, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 98\n",
            "x_batch size is torch.Size([27, 4000])\n",
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([27, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([27, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0683, grad_fn=<NllLossBackward>)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0036)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0712)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1018)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0891)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0131)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1081)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1493)\n",
            "validation loop :: epoch is 98\n",
            "output shape before fc torch.Size([31, 4000, 4000])\n",
            "shape of output torch.Size([31, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([31, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([31, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0726)\n",
            "Epoch 98 : trainloss 1.075049750506878 : val loss 1.076099619269371\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0353, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0944, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0838, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1039, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0585, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1218, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0807, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0796, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0799],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0722, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0617, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0754, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0269, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1113, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0490, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0490, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0448, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0701, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0986, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0902, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0311, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1482, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0353, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0764, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 99\n",
            "x_batch size is torch.Size([27, 4000])\n",
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([27, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([27, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1096, grad_fn=<NllLossBackward>)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0944)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0617)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0574)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0448)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]]) \n",
            "loss is (validation) tensor(1.0669)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0754)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1398)\n",
            "validation loop :: epoch is 99\n",
            "output shape before fc torch.Size([31, 4000, 4000])\n",
            "shape of output torch.Size([31, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([31, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([31, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0683)\n",
            "Epoch 99 : trainloss 1.0753182768821716 : val loss 1.07608263194561\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0364, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0902, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1039, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0669, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1165, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0880, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0659, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0799],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0437, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0807, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0490, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0437, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0860, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0627, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0543, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0975, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0437, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1260, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1176, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0617, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0986, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0933, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(0.9994, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0627, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 100\n",
            "x_batch size is torch.Size([27, 4000])\n",
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([27, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([27, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1208, grad_fn=<NllLossBackward>)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0627)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0258)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0849)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1070)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0902)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0754)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0986)\n",
            "validation loop :: epoch is 100\n",
            "output shape before fc torch.Size([31, 4000, 4000])\n",
            "shape of output torch.Size([31, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([31, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([31, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0639)\n",
            "Epoch 100 : trainloss 1.0753915806611378 : val loss 1.0760656297206879\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0501, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1239, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0944, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0944, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0448, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1113, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0490, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0712, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0986, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(0.9857, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0712, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0617, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0479, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0891, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0912, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0142, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1345, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1429, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0712, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1060, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0142, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0574, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.0669, grad_fn=<NllLossBackward>)\n",
            "training loop :: epoch is 101\n",
            "x_batch size is torch.Size([27, 4000])\n",
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([27, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([27, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]], grad_fn=<AddmmBackward>) \n",
            "loss is  tensor(1.1171, grad_fn=<NllLossBackward>)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0754)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0574)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0311)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1113)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.1387)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0554)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([32, 4000, 4000])\n",
            "shape of output torch.Size([32, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([32, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([32, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801]]) \n",
            "loss is (validation) tensor(1.0807)\n",
            "validation loop :: epoch is 101\n",
            "output shape before fc torch.Size([31, 4000, 4000])\n",
            "shape of output torch.Size([31, 1, 100])\n",
            "shape of out before fc_LSTM is torch.Size([31, 1, 100])\n",
            "shape of out after fc_LSTM is torch.Size([31, 3])\n",
            "final output is tensor([[ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3590,  0.0801],\n",
            "        [ 0.2150, -0.3589,  0.0800]]) \n",
            "loss is (validation) tensor(1.0585)\n",
            "Epoch 101 : trainloss 1.0753672793507576 : val loss 1.0760442316532135\n",
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n",
            "output shape before fc torch.Size([27, 4000, 4000])\n",
            "shape of output torch.Size([27, 1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8XgSEQwxQsKK",
        "outputId": "a01f5ec8-ea9e-4f65-a0dd-b786907c046e"
      },
      "source": [
        "ax = plt.figure().gca()\n",
        "\n",
        "ax.plot(history['train'])\n",
        "ax.plot(history['val'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.title('Loss over epochs')\n",
        "#plt.show()\n",
        "plt.savefig('Loss_over_epochs.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zv4KePcQ8_hf",
        "outputId": "23b5b136-f221-4cc4-c06a-46163641ac8a"
      },
      "source": [
        "history = dict(train =[], val = [])\n",
        "best_loss = 1\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "for epochs in range(1, n_epochs+1):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  if epochs in range(3):\n",
        "    for x_batch,y_batch in train_dl:\n",
        "      print(f'training loop :: epoch is {epochs}')\n",
        "      model.train()\n",
        "      print(f'x_batch size is {x_batch.size()}')\n",
        "      x_batch = x_batch.unsqueeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      out = model(x_batch)\n",
        "      print(\"out is \",out)\n",
        "      print(\"y_batch is \", y_batch)\n",
        "      loss = criteria(out,y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_losses.append(loss.item())\n",
        "    #if i % 5 == 0:\n",
        "     # print(\"iteration %d, epochs %d,loss = %.4f\" %(i,epochs,loss.item()))\n",
        "    with torch.no_grad():\n",
        "      for x_val,y_val in valid_dl:\n",
        "        print(f'validation loop :: epoch is {epochs}')\n",
        "        model.eval()\n",
        "        x_val =x_val.unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        out = model(x_val)\n",
        "        print(\"out_val is :\", out)\n",
        "        print(\"y_val is \",y_val)\n",
        "        loss = criteria(out,y_val)\n",
        "        val_losses.append(loss.item())\n",
        "    \n",
        "    train_loss = np.mean(train_losses)\n",
        "    val_loss = np.mean(val_losses)\n",
        "\n",
        "    history['train'].append(train_loss)\n",
        "    history['val'].append(val_loss)\n",
        "\n",
        "    #if val_loss < best_loss:\n",
        "    # best_loss = val_lossesbest_model_wts = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    print(f'Epoch {epochs} : trainloss {train_loss} : val loss {val_loss}')\n",
        "    #writer.add_scalars('Training vs validation Loss',\n",
        "     #                   {'Training' : loss},\n",
        "      #                  epochs *len( history['train']))\n",
        "\n",
        "  writer.flush()\n",
        "  writer.add_graph(model,x_batch)\n",
        "  writer.close()\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loop :: epoch is 1\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "out is  tensor([[-0.0196,  0.0070, -0.0059],\n",
            "        [-0.0199,  0.0067, -0.0053],\n",
            "        [-0.0197,  0.0068, -0.0053],\n",
            "        [-0.0196,  0.0068, -0.0057],\n",
            "        [-0.0196,  0.0072, -0.0054],\n",
            "        [-0.0199,  0.0064, -0.0051],\n",
            "        [-0.0191,  0.0068, -0.0056],\n",
            "        [-0.0192,  0.0075, -0.0062],\n",
            "        [-0.0198,  0.0068, -0.0055],\n",
            "        [-0.0197,  0.0068, -0.0053],\n",
            "        [-0.0196,  0.0065, -0.0053],\n",
            "        [-0.0196,  0.0069, -0.0055],\n",
            "        [-0.0198,  0.0068, -0.0055],\n",
            "        [-0.0198,  0.0068, -0.0057],\n",
            "        [-0.0196,  0.0069, -0.0054],\n",
            "        [-0.0196,  0.0067, -0.0052],\n",
            "        [-0.0197,  0.0067, -0.0056],\n",
            "        [-0.0198,  0.0068, -0.0054],\n",
            "        [-0.0191,  0.0079, -0.0054],\n",
            "        [-0.0199,  0.0073, -0.0055],\n",
            "        [-0.0196,  0.0070, -0.0057],\n",
            "        [-0.0196,  0.0069, -0.0055],\n",
            "        [-0.0195,  0.0068, -0.0053],\n",
            "        [-0.0197,  0.0070, -0.0055],\n",
            "        [-0.0197,  0.0069, -0.0053],\n",
            "        [-0.0199,  0.0070, -0.0056],\n",
            "        [-0.0197,  0.0070, -0.0052],\n",
            "        [-0.0197,  0.0069, -0.0055],\n",
            "        [-0.0198,  0.0069, -0.0055],\n",
            "        [-0.0199,  0.0067, -0.0054],\n",
            "        [-0.0199,  0.0067, -0.0053],\n",
            "        [-0.0197,  0.0070, -0.0055]], grad_fn=<AddmmBackward>)\n",
            "y_batch is  tensor([0, 2, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1,\n",
            "        2, 1, 0, 2, 2, 0, 2, 2])\n",
            "training loop :: epoch is 1\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "out is  tensor([[-0.0192,  0.0076, -0.0071],\n",
            "        [-0.0192,  0.0079, -0.0072],\n",
            "        [-0.0191,  0.0077, -0.0072],\n",
            "        [-0.0187,  0.0075, -0.0075],\n",
            "        [-0.0193,  0.0078, -0.0071],\n",
            "        [-0.0196,  0.0077, -0.0073],\n",
            "        [-0.0190,  0.0074, -0.0073],\n",
            "        [-0.0193,  0.0083, -0.0073],\n",
            "        [-0.0190,  0.0078, -0.0072],\n",
            "        [-0.0192,  0.0075, -0.0073],\n",
            "        [-0.0190,  0.0075, -0.0072],\n",
            "        [-0.0194,  0.0078, -0.0068],\n",
            "        [-0.0198,  0.0083, -0.0073],\n",
            "        [-0.0189,  0.0075, -0.0072],\n",
            "        [-0.0193,  0.0076, -0.0072],\n",
            "        [-0.0190,  0.0080, -0.0072],\n",
            "        [-0.0189,  0.0081, -0.0059],\n",
            "        [-0.0184,  0.0078, -0.0068],\n",
            "        [-0.0186,  0.0074, -0.0074],\n",
            "        [-0.0192,  0.0075, -0.0071],\n",
            "        [-0.0184,  0.0074, -0.0074],\n",
            "        [-0.0192,  0.0073, -0.0070],\n",
            "        [-0.0192,  0.0075, -0.0073],\n",
            "        [-0.0220,  0.0067, -0.0081],\n",
            "        [-0.0194,  0.0077, -0.0071],\n",
            "        [-0.0192,  0.0076, -0.0071],\n",
            "        [-0.0192,  0.0076, -0.0074],\n",
            "        [-0.0193,  0.0076, -0.0074],\n",
            "        [-0.0192,  0.0079, -0.0071],\n",
            "        [-0.0187,  0.0080, -0.0071],\n",
            "        [-0.0179,  0.0073, -0.0077],\n",
            "        [-0.0191,  0.0075, -0.0073]], grad_fn=<AddmmBackward>)\n",
            "y_batch is  tensor([1, 0, 2, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0,\n",
            "        0, 2, 1, 2, 0, 0, 0, 0])\n",
            "training loop :: epoch is 1\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "out is  tensor([[-0.0139,  0.0029, -0.0080],\n",
            "        [-0.0132,  0.0030, -0.0080],\n",
            "        [-0.0146,  0.0028, -0.0073],\n",
            "        [-0.0141,  0.0029, -0.0079],\n",
            "        [-0.0139,  0.0029, -0.0078],\n",
            "        [-0.0138,  0.0030, -0.0077],\n",
            "        [-0.0134,  0.0025, -0.0078],\n",
            "        [-0.0143,  0.0029, -0.0082],\n",
            "        [-0.0143,  0.0030, -0.0077],\n",
            "        [-0.0140,  0.0029, -0.0078],\n",
            "        [-0.0136,  0.0033, -0.0085],\n",
            "        [-0.0139,  0.0027, -0.0074],\n",
            "        [-0.0139,  0.0030, -0.0080],\n",
            "        [-0.0140,  0.0028, -0.0079],\n",
            "        [-0.0138,  0.0026, -0.0081],\n",
            "        [-0.0139,  0.0028, -0.0078],\n",
            "        [-0.0139,  0.0032, -0.0078],\n",
            "        [-0.0129,  0.0029, -0.0087],\n",
            "        [-0.0141,  0.0027, -0.0077],\n",
            "        [-0.0145,  0.0037, -0.0075],\n",
            "        [-0.0139,  0.0029, -0.0079],\n",
            "        [-0.0139,  0.0029, -0.0080],\n",
            "        [-0.0138,  0.0028, -0.0079],\n",
            "        [-0.0140,  0.0029, -0.0076],\n",
            "        [-0.0140,  0.0030, -0.0080],\n",
            "        [-0.0142,  0.0026, -0.0077],\n",
            "        [-0.0137,  0.0028, -0.0080],\n",
            "        [-0.0142,  0.0029, -0.0079],\n",
            "        [-0.0140,  0.0025, -0.0084],\n",
            "        [-0.0139,  0.0029, -0.0079],\n",
            "        [-0.0135,  0.0024, -0.0082],\n",
            "        [-0.0137,  0.0022, -0.0087]], grad_fn=<AddmmBackward>)\n",
            "y_batch is  tensor([2, 0, 0, 0, 1, 2, 0, 1, 2, 1, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        2, 1, 2, 2, 0, 2, 0, 0])\n",
            "training loop :: epoch is 1\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "out is  tensor([[-0.0018, -0.0050, -0.0126],\n",
            "        [-0.0018, -0.0049, -0.0127],\n",
            "        [-0.0028, -0.0043, -0.0120],\n",
            "        [-0.0017, -0.0047, -0.0124],\n",
            "        [-0.0017, -0.0048, -0.0125],\n",
            "        [-0.0018, -0.0048, -0.0127],\n",
            "        [-0.0016, -0.0048, -0.0127],\n",
            "        [-0.0022, -0.0046, -0.0124],\n",
            "        [-0.0020, -0.0049, -0.0126],\n",
            "        [-0.0019, -0.0047, -0.0125],\n",
            "        [-0.0016, -0.0048, -0.0126],\n",
            "        [-0.0019, -0.0047, -0.0127],\n",
            "        [-0.0012, -0.0052, -0.0130],\n",
            "        [-0.0020, -0.0050, -0.0122],\n",
            "        [-0.0020, -0.0048, -0.0126],\n",
            "        [-0.0023, -0.0043, -0.0119],\n",
            "        [-0.0021, -0.0047, -0.0123],\n",
            "        [-0.0017, -0.0049, -0.0129],\n",
            "        [-0.0016, -0.0049, -0.0128],\n",
            "        [-0.0010, -0.0047, -0.0130],\n",
            "        [-0.0021, -0.0051, -0.0122],\n",
            "        [-0.0023, -0.0048, -0.0123],\n",
            "        [-0.0021, -0.0048, -0.0123],\n",
            "        [-0.0016, -0.0049, -0.0127],\n",
            "        [-0.0015, -0.0049, -0.0129],\n",
            "        [-0.0020, -0.0047, -0.0123],\n",
            "        [-0.0005, -0.0051, -0.0134],\n",
            "        [-0.0034, -0.0046, -0.0101],\n",
            "        [-0.0020, -0.0050, -0.0122],\n",
            "        [-0.0018, -0.0049, -0.0124],\n",
            "        [-0.0019, -0.0048, -0.0126],\n",
            "        [-0.0020, -0.0048, -0.0124]], grad_fn=<AddmmBackward>)\n",
            "y_batch is  tensor([2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 1, 2, 2,\n",
            "        0, 1, 0, 0, 1, 2, 2, 2])\n",
            "training loop :: epoch is 1\n",
            "x_batch size is torch.Size([32, 4000])\n",
            "out is  tensor([[ 0.0023, -0.0287,  0.0074],\n",
            "        [ 0.0030, -0.0293,  0.0079],\n",
            "        [ 0.0018, -0.0285,  0.0080],\n",
            "        [ 0.0018, -0.0284,  0.0081],\n",
            "        [ 0.0035, -0.0286,  0.0072],\n",
            "        [ 0.0022, -0.0291,  0.0077],\n",
            "        [ 0.0027, -0.0286,  0.0071],\n",
            "        [ 0.0023, -0.0288,  0.0077],\n",
            "        [ 0.0027, -0.0292,  0.0072],\n",
            "        [ 0.0021, -0.0288,  0.0079],\n",
            "        [ 0.0019, -0.0287,  0.0076],\n",
            "        [ 0.0041, -0.0295,  0.0079],\n",
            "        [ 0.0022, -0.0281,  0.0073],\n",
            "        [ 0.0024, -0.0288,  0.0074],\n",
            "        [ 0.0024, -0.0295,  0.0078],\n",
            "        [ 0.0027, -0.0287,  0.0073],\n",
            "        [ 0.0030, -0.0290,  0.0067],\n",
            "        [ 0.0020, -0.0283,  0.0075],\n",
            "        [ 0.0024, -0.0288,  0.0071],\n",
            "        [ 0.0022, -0.0287,  0.0077],\n",
            "        [ 0.0045, -0.0292,  0.0061],\n",
            "        [ 0.0025, -0.0289,  0.0072],\n",
            "        [ 0.0025, -0.0289,  0.0074],\n",
            "        [ 0.0041, -0.0293,  0.0064],\n",
            "        [ 0.0026, -0.0288,  0.0073],\n",
            "        [ 0.0019, -0.0294,  0.0089],\n",
            "        [ 0.0022, -0.0290,  0.0077],\n",
            "        [ 0.0028, -0.0293,  0.0062],\n",
            "        [ 0.0025, -0.0286,  0.0074],\n",
            "        [ 0.0025, -0.0292,  0.0083],\n",
            "        [ 0.0021, -0.0288,  0.0077],\n",
            "        [ 0.0022, -0.0297,  0.0089]], grad_fn=<AddmmBackward>)\n",
            "y_batch is  tensor([2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 2, 2, 0,\n",
            "        2, 0, 2, 0, 2, 1, 2, 0])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-70574a068e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_batch is \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "fuQtd6Wo-9Rw",
        "outputId": "4221aa23-f2a2-472c-a8bf-0e1d7b25b038"
      },
      "source": [
        "history = dict(train =[], val = [])\n",
        "best_loss = 1\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "for epochs in range(1, n_epochs+1):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  for x_batch,y_batch in train_dl:\n",
        "    print(f'training loop :: epoch is {epochs}')\n",
        "    model.train()\n",
        "    x_batch = x_batch.unsqueeze(1)\n",
        "    optimizer.zero_grad()\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model(x_batch)\n",
        "    loss = criteria(out,y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "    #if i % 5 == 0:\n",
        "     # print(\"iteration %d, epochs %d,loss = %.4f\" %(i,epochs,loss.item()))\n",
        "  with torch.no_grad():\n",
        "    for x_val,y_val in valid_dl:\n",
        "      print(f'validation loop :: epoch is {epochs}')\n",
        "      model.eval()\n",
        "      x_val =x_val.unsqueeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      x_val = x_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "      out = model(x_val)\n",
        "      loss = criteria(out,y_val)\n",
        "      val_losses.append(loss.item())\n",
        "  \n",
        "  train_loss = np.mean(train_losses)\n",
        "  val_loss = np.mean(val_losses)\n",
        "\n",
        "  history['train'].append(train_loss)\n",
        "  history['val'].append(val_loss)\n",
        "\n",
        "  #if val_loss < best_loss:\n",
        "   # best_loss = val_lossesbest_model_wts = copy.deepcopy(model.state_dict())\n",
        "  \n",
        "  print(f'Epoch {epochs} : trainloss {train_loss} : val loss {val_loss}')\n",
        "  writer.add_scalars('Training vs validation Loss',\n",
        "                       {'Training' : loss},\n",
        "                       epochs *len( history['train']))\n",
        "\n",
        "writer.flush()\n",
        "writer.add_graph(model,x_batch)\n",
        "writer.close()\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n",
            "training loop :: epoch is 1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-484d966c987c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-c030ce43d30d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(\"out_size fc_cnn\",out2.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(\"h0,c0 size\", h0.size(),c0.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(\"output shape lstm\",out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#output's dimension has been reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njwyDWpFdbpU",
        "outputId": "6b881d1d-6aa4-474c-86f8-6083604960eb"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('cnn.weight', tensor([[[3.5070]]])),\n",
              "             ('cnn.bias', tensor([0.1062])),\n",
              "             ('fc.weight',\n",
              "              tensor([[-2.6621e-02, -4.4411e-02, -5.3176e-02,  ...,  2.9087e-02,\n",
              "                        6.2047e-02,  5.7984e-02],\n",
              "                      [ 4.1843e-02,  6.2076e-02,  8.6345e-02,  ...,  5.6072e-02,\n",
              "                        3.6729e-02,  4.8194e-02],\n",
              "                      [-3.2800e-03,  8.6702e-03,  7.6439e-03,  ..., -2.1715e-02,\n",
              "                       -1.4851e-02, -1.7354e-02],\n",
              "                      ...,\n",
              "                      [ 3.7215e-02, -1.0306e-03, -1.4038e-03,  ...,  1.2648e-02,\n",
              "                       -5.9738e-03,  1.5882e-02],\n",
              "                      [ 6.3928e-02,  6.3521e-02,  7.7119e-02,  ...,  2.4966e-05,\n",
              "                        1.2192e-02,  2.2303e-02],\n",
              "                      [ 9.6691e-02,  9.9952e-02,  1.0562e-01,  ...,  6.1575e-02,\n",
              "                        4.7147e-02,  3.2291e-02]])),\n",
              "             ('fc.bias',\n",
              "              tensor([-5.9753e-03, -7.3976e-03,  1.4678e-03, -5.1300e-03, -2.2154e-03,\n",
              "                      -1.0168e-02, -2.3669e-02,  2.0436e-03, -7.0628e-04, -6.8206e-04,\n",
              "                      -1.0856e-02,  1.7898e-02, -5.5852e-04, -1.1149e-02, -9.4644e-03,\n",
              "                      -1.2083e-02, -1.4031e-02,  2.3202e-02, -5.9382e-03, -1.7873e-02,\n",
              "                      -1.2456e-02, -1.8748e-02,  1.7866e-03,  5.1528e-03, -1.6223e-02,\n",
              "                       1.9889e-04, -3.9381e-02,  1.1620e-02,  6.7129e-03, -7.0340e-03,\n",
              "                      -1.8126e-02, -1.1189e-02,  2.7461e-03,  7.2018e-03,  6.8212e-03,\n",
              "                      -1.1693e-03, -6.7675e-04, -1.4776e-03,  7.5070e-03, -3.4454e-03,\n",
              "                       1.2176e-02,  7.9821e-03,  5.7618e-03,  1.8425e-03, -1.2882e-02,\n",
              "                      -1.1622e-02,  1.7838e-02, -8.8296e-03, -2.6383e-03, -8.0520e-03,\n",
              "                       1.2708e-02,  8.6482e-03, -1.8827e-02, -1.0935e-02,  5.0832e-03,\n",
              "                      -7.0430e-03, -1.0734e-02,  1.2654e-02,  9.5212e-03,  4.0615e-03,\n",
              "                       7.7598e-03, -1.1892e-02, -1.2926e-02,  6.8072e-03,  7.5168e-03,\n",
              "                      -1.3169e-02, -3.4499e-03,  1.8510e-03, -1.5550e-02,  1.6163e-02,\n",
              "                       5.2202e-03, -2.0461e-02,  1.8266e-02,  1.2384e-02, -1.2889e-02,\n",
              "                       3.9799e-03,  5.9759e-03,  2.9399e-05, -7.8447e-03,  6.4988e-03,\n",
              "                      -1.3692e-02, -1.5513e-02,  4.0907e-03, -2.5257e-02, -1.4639e-02,\n",
              "                       1.1811e-02,  2.6026e-03, -2.9649e-03,  1.8598e-02, -1.2914e-03,\n",
              "                      -1.2881e-02, -2.5671e-02, -1.9188e-02,  7.8954e-03, -1.0076e-02,\n",
              "                      -2.2071e-03,  6.7812e-03,  2.9373e-03,  1.0698e-02,  1.1074e-02])),\n",
              "             ('lstm.weight_ih_l0',\n",
              "              tensor([[ 0.0457,  0.0085, -0.0036,  ...,  0.0084,  0.0166,  0.0076],\n",
              "                      [-0.0530, -0.0526,  0.0196,  ..., -0.0395, -0.0013,  0.0006],\n",
              "                      [ 0.0038, -0.0364, -0.0397,  ..., -0.0078, -0.0518, -0.0183],\n",
              "                      ...,\n",
              "                      [ 0.0178,  0.0358, -0.0063,  ..., -0.0061,  0.0256,  0.0650],\n",
              "                      [-0.0340,  0.0217,  0.0485,  ..., -0.0778, -0.0202, -0.0081],\n",
              "                      [-0.0213, -0.0207, -0.0049,  ..., -0.0155, -0.0247, -0.0253]])),\n",
              "             ('lstm.weight_hh_l0',\n",
              "              tensor([[ 0.0073, -0.0074,  0.0119,  ...,  0.0064,  0.0078, -0.0123],\n",
              "                      [-0.0142,  0.0155,  0.0004,  ..., -0.0037,  0.0040,  0.0005],\n",
              "                      [ 0.0119,  0.0029,  0.0120,  ..., -0.0146, -0.0141,  0.0009],\n",
              "                      ...,\n",
              "                      [-0.0118, -0.0148,  0.0099,  ..., -0.0064, -0.0031,  0.0025],\n",
              "                      [ 0.0133,  0.0033, -0.0014,  ..., -0.0060, -0.0089,  0.0101],\n",
              "                      [-0.0109,  0.0054,  0.0126,  ..., -0.0026, -0.0033,  0.0130]])),\n",
              "             ('lstm.bias_ih_l0',\n",
              "              tensor([-0.0590,  0.0246, -0.0718,  ..., -0.0460, -0.0861, -0.0830])),\n",
              "             ('lstm.bias_hh_l0',\n",
              "              tensor([-0.0562,  0.0062, -0.0679,  ..., -0.0372, -0.1038, -0.0910])),\n",
              "             ('fc1.weight',\n",
              "              tensor([[ 0.0220,  0.0211, -0.0058,  ..., -0.0151, -0.0465,  0.0027],\n",
              "                      [-0.0057, -0.0467,  0.0076,  ...,  0.0027,  0.0057,  0.0086],\n",
              "                      [-0.0022, -0.0077,  0.0216,  ..., -0.0074,  0.0138, -0.0262]])),\n",
              "             ('fc1.bias', tensor([-0.0159, -0.0291,  0.0080]))])"
            ]
          },
          "execution_count": 56,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9t4fnUCtlzM",
        "outputId": "b2d2d158-72fc-4e48-aaf3-b8d82ad5dbb3"
      },
      "source": [
        "history['val']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4.2702222019433975,\n",
              " 4.262030273675919,\n",
              " 4.289130687713623,\n",
              " 4.352687656879425,\n",
              " 4.2523631155490875,\n",
              " 4.42069411277771,\n",
              " 4.468575805425644,\n",
              " 4.481773883104324,\n",
              " 4.502141624689102,\n",
              " 4.500783443450928,\n",
              " 4.477127432823181,\n",
              " 4.619614869356155,\n",
              " 4.5841231644153595,\n",
              " 4.487133055925369,\n",
              " 4.609535127878189,\n",
              " 4.547390282154083,\n",
              " 4.675490468740463,\n",
              " 4.658600091934204,\n",
              " 4.606040865182877,\n",
              " 4.68226033449173,\n",
              " 4.645402163267136,\n",
              " 4.684078067541122,\n",
              " 4.875272274017334,\n",
              " 4.8126852214336395,\n",
              " 4.811688721179962,\n",
              " 4.905931293964386,\n",
              " 4.88066041469574,\n",
              " 5.049883097410202,\n",
              " 5.037159353494644,\n",
              " 4.924504667520523,\n",
              " 5.015293061733246,\n",
              " 5.017097055912018,\n",
              " 4.890299946069717,\n",
              " 4.981059193611145,\n",
              " 5.157070815563202,\n",
              " 5.393358677625656,\n",
              " 5.184930711984634,\n",
              " 5.5330159068107605,\n",
              " 5.607106864452362,\n",
              " 5.410694748163223,\n",
              " 5.463030934333801,\n",
              " 5.489333540201187,\n",
              " 5.646244645118713,\n",
              " 5.670216590166092,\n",
              " 5.72143429517746,\n",
              " 5.755019903182983,\n",
              " 5.741957008838654,\n",
              " 5.803092896938324,\n",
              " 5.828267216682434,\n",
              " 5.837239325046539,\n",
              " 5.829177975654602,\n",
              " 5.897054672241211,\n",
              " 5.883362889289856,\n",
              " 5.910471260547638,\n",
              " 5.930069446563721,\n",
              " 5.9390445947647095,\n",
              " 5.9241547882556915,\n",
              " 6.017766177654266,\n",
              " 5.987569451332092,\n",
              " 5.997286468744278,\n",
              " 6.042075037956238,\n",
              " 6.034159779548645,\n",
              " 6.0418254137039185,\n",
              " 6.07307094335556,\n",
              " 6.082359969615936,\n",
              " 6.090170860290527,\n",
              " 6.078805983066559,\n",
              " 6.14118367433548,\n",
              " 6.133918404579163,\n",
              " 6.138602256774902,\n",
              " 6.14206999540329,\n",
              " 6.163207232952118,\n",
              " 6.163761019706726,\n",
              " 6.201077520847321,\n",
              " 6.206050217151642,\n",
              " 6.20588281750679,\n",
              " 6.2232131361961365,\n",
              " 6.222122699022293,\n",
              " 6.231277585029602,\n",
              " 6.234760522842407,\n",
              " 6.290812194347382,\n",
              " 6.26251745223999,\n",
              " 6.293483674526215,\n",
              " 6.284206956624985,\n",
              " 6.288527965545654,\n",
              " 6.316815286874771,\n",
              " 6.318536698818207,\n",
              " 6.33000636100769,\n",
              " 6.3488315641880035,\n",
              " 6.355628788471222,\n",
              " 6.361281156539917,\n",
              " 6.369597315788269,\n",
              " 6.373896658420563,\n",
              " 6.378616511821747,\n",
              " 6.4051313400268555,\n",
              " 6.408582091331482,\n",
              " 6.416681230068207,\n",
              " 6.424511253833771,\n",
              " 6.440624475479126,\n",
              " 6.447867810726166,\n",
              " 6.465429812669754]"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Zdo5l-aMLcGN",
        "outputId": "a77af208-78e3-4dab-9123-3189e46808c5"
      },
      "source": [
        "\n",
        "ax = plt.figure().gca()\n",
        "\n",
        "ax.plot(history['train'])\n",
        "ax.plot(history['val'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.title('Loss over epochs')\n",
        "#plt.show()\n",
        "plt.savefig('Loss_over_epochs.png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0AHdgrHI_kM",
        "outputId": "9fa7ecf3-9a69-4d3b-c310-98597e47a644"
      },
      "source": [
        "for epochs in range(1, n_epochs+1):\n",
        "  train_losses = []\n",
        "  for i, (x_batch,y_batch) in enumerate(train_dl):\n",
        "    \n",
        "    print(\"i=\", i)\n",
        "    model.train()\n",
        "    x_batch = x_batch.unsqueeze(1)\n",
        "    #print(\"x_batch size\",x_batch.size())\n",
        "    optimizer.zero_grad()\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model(x_batch)\n",
        "    #print(out.size())\n",
        "    #print(y_batch.size())\n",
        "    loss = criteria(out,y_batch)\n",
        "    #print(\"loss\",loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "    if i % 5 == 0:\n",
        "      print(\"iteration %d, epochs %d,loss = %.4f\" %(i,epochs,loss.item()))\n",
        "    total = 0.0\n",
        "  correct = 0.0\n",
        "  val_losses = []\n",
        "  with torch.no_grad():\n",
        "    for x_val,y_val in valid_dl:\n",
        "      model.eval()\n",
        "      x_val =x_val.unsqueeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      x_val = x_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "      out = model(x_val)\n",
        "      y_val = torch.unsqueeze(y_val,0)\n",
        "      preds = F.log_softmax(out, dim=1).argmax(dim = 1)\n",
        "      total = total + y_val.size(1)\n",
        "      correct += (preds == y_val).sum().item()\n",
        "    acc = correct/total\n",
        "    print(f'accuracy is {acc:2.2%} epoch is  {epochs}')\n",
        "    acc1 =[]\n",
        "    acc1.append(acc)\n",
        "\n",
        "  writer.add_scalars('Training vs validation Loss',\n",
        "                       {'Training' : loss},\n",
        "                       epochs *len(train_dl)+i)\n",
        "\n",
        "writer.flush()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i= 0\n",
            "iteration 0, epochs 1,loss = 0.1079\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 1,loss = 0.2214\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 1,loss = 0.1924\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 1,loss = 0.1320\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 1,loss = 0.1200\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 53.73% epoch is  1\n",
            "i= 0\n",
            "iteration 0, epochs 2,loss = 0.1098\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 2,loss = 0.0163\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 2,loss = 0.1062\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 2,loss = 0.2478\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 2,loss = 0.1413\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 51.37% epoch is  2\n",
            "i= 0\n",
            "iteration 0, epochs 3,loss = 0.0797\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 3,loss = 0.1313\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 3,loss = 0.3884\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 3,loss = 0.1313\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 3,loss = 0.1082\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 53.73% epoch is  3\n",
            "i= 0\n",
            "iteration 0, epochs 4,loss = 0.0126\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 4,loss = 0.3305\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 4,loss = 0.3663\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 4,loss = 0.0535\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 4,loss = 0.0381\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 56.47% epoch is  4\n",
            "i= 0\n",
            "iteration 0, epochs 5,loss = 0.1330\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 5,loss = 0.0164\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 5,loss = 0.1598\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 5,loss = 0.0153\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 5,loss = 0.1256\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.16% epoch is  5\n",
            "i= 0\n",
            "iteration 0, epochs 6,loss = 0.0827\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 6,loss = 0.0264\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 6,loss = 0.1495\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 6,loss = 0.1293\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 6,loss = 0.1173\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.16% epoch is  6\n",
            "i= 0\n",
            "iteration 0, epochs 7,loss = 0.0328\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 7,loss = 0.1296\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 7,loss = 0.0769\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 7,loss = 0.0527\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 7,loss = 0.0603\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.16% epoch is  7\n",
            "i= 0\n",
            "iteration 0, epochs 8,loss = 0.0185\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 8,loss = 0.0306\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 8,loss = 0.0493\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 8,loss = 0.4688\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 8,loss = 0.0143\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.20% epoch is  8\n",
            "i= 0\n",
            "iteration 0, epochs 9,loss = 0.5312\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 9,loss = 0.0322\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 9,loss = 0.0147\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 9,loss = 0.0204\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 9,loss = 0.2086\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.55% epoch is  9\n",
            "i= 0\n",
            "iteration 0, epochs 10,loss = 0.1179\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 10,loss = 0.0089\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 10,loss = 0.0697\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 10,loss = 0.0745\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 10,loss = 0.0703\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.98% epoch is  10\n",
            "i= 0\n",
            "iteration 0, epochs 11,loss = 0.0074\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 11,loss = 0.0207\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 11,loss = 0.0168\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 11,loss = 0.0048\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 11,loss = 0.0847\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.94% epoch is  11\n",
            "i= 0\n",
            "iteration 0, epochs 12,loss = 0.0071\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 12,loss = 0.0191\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 12,loss = 0.0064\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 12,loss = 0.0064\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 12,loss = 0.0041\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.16% epoch is  12\n",
            "i= 0\n",
            "iteration 0, epochs 13,loss = 0.0050\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 13,loss = 0.0068\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 13,loss = 0.0034\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 13,loss = 0.0028\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 13,loss = 0.0030\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 52.16% epoch is  13\n",
            "i= 0\n",
            "iteration 0, epochs 14,loss = 0.0032\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 14,loss = 0.0044\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 14,loss = 0.0016\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 14,loss = 0.0109\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 14,loss = 0.0022\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 51.76% epoch is  14\n",
            "i= 0\n",
            "iteration 0, epochs 15,loss = 0.0035\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 15,loss = 0.0022\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 15,loss = 0.0036\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 15,loss = 0.0045\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 15,loss = 0.0022\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.98% epoch is  15\n",
            "i= 0\n",
            "iteration 0, epochs 16,loss = 0.0019\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 16,loss = 0.0038\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 16,loss = 0.1319\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 16,loss = 0.0012\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 16,loss = 0.0065\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.98% epoch is  16\n",
            "i= 0\n",
            "iteration 0, epochs 17,loss = 0.0018\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 17,loss = 0.0021\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 17,loss = 0.0021\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 17,loss = 0.0010\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 17,loss = 0.0038\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.59% epoch is  17\n",
            "i= 0\n",
            "iteration 0, epochs 18,loss = 0.0020\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 18,loss = 0.0019\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 18,loss = 0.0003\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 18,loss = 0.0009\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 18,loss = 0.0016\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.59% epoch is  18\n",
            "i= 0\n",
            "iteration 0, epochs 19,loss = 0.0014\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 19,loss = 0.0028\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 19,loss = 0.0013\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 19,loss = 0.0021\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 19,loss = 0.1357\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 51.37% epoch is  19\n",
            "i= 0\n",
            "iteration 0, epochs 20,loss = 0.0013\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 20,loss = 0.0029\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 20,loss = 0.0020\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 20,loss = 0.0023\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 20,loss = 0.0046\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 50.20% epoch is  20\n",
            "i= 0\n",
            "iteration 0, epochs 21,loss = 0.0013\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 21,loss = 0.0046\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 21,loss = 0.0028\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 21,loss = 0.0024\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 21,loss = 0.0013\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  21\n",
            "i= 0\n",
            "iteration 0, epochs 22,loss = 0.0015\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 22,loss = 0.0003\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 22,loss = 0.0017\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 22,loss = 0.0006\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 22,loss = 0.0007\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  22\n",
            "i= 0\n",
            "iteration 0, epochs 23,loss = 0.0014\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 23,loss = 0.0010\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 23,loss = 0.0015\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 23,loss = 0.0011\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 23,loss = 0.1085\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  23\n",
            "i= 0\n",
            "iteration 0, epochs 24,loss = 0.0013\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 24,loss = 0.0013\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 24,loss = 0.0022\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 24,loss = 0.0022\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 24,loss = 0.0021\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  24\n",
            "i= 0\n",
            "iteration 0, epochs 25,loss = 0.0017\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 25,loss = 0.0022\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 25,loss = 0.0024\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 25,loss = 0.0009\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 25,loss = 0.0008\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.02% epoch is  25\n",
            "i= 0\n",
            "iteration 0, epochs 26,loss = 0.0008\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 26,loss = 0.0006\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 26,loss = 0.0015\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 26,loss = 0.0005\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 26,loss = 0.0016\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.41% epoch is  26\n",
            "i= 0\n",
            "iteration 0, epochs 27,loss = 0.0019\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 27,loss = 0.0017\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 27,loss = 0.0016\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 27,loss = 0.0013\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 27,loss = 0.0017\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.41% epoch is  27\n",
            "i= 0\n",
            "iteration 0, epochs 28,loss = 0.0015\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 28,loss = 0.0020\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 28,loss = 0.0016\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 28,loss = 0.0037\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 28,loss = 0.0047\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.41% epoch is  28\n",
            "i= 0\n",
            "iteration 0, epochs 29,loss = 0.0014\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 29,loss = 0.0007\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 29,loss = 0.0006\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 29,loss = 0.0011\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 29,loss = 0.0012\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  29\n",
            "i= 0\n",
            "iteration 0, epochs 30,loss = 0.0008\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 30,loss = 0.0006\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 30,loss = 0.0019\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 30,loss = 0.0017\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 30,loss = 0.0016\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  30\n",
            "i= 0\n",
            "iteration 0, epochs 31,loss = 0.0015\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 31,loss = 0.0011\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 31,loss = 0.0005\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 31,loss = 0.0005\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 31,loss = 0.0004\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.80% epoch is  31\n",
            "i= 0\n",
            "iteration 0, epochs 32,loss = 0.0006\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 32,loss = 0.0004\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 32,loss = 0.0008\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 32,loss = 0.0037\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 32,loss = 0.0018\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 48.63% epoch is  32\n",
            "i= 0\n",
            "iteration 0, epochs 33,loss = 0.0008\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 33,loss = 0.0007\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 33,loss = 0.0006\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 33,loss = 0.0005\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 33,loss = 0.0007\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.02% epoch is  33\n",
            "i= 0\n",
            "iteration 0, epochs 34,loss = 0.0007\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 34,loss = 0.0006\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 34,loss = 0.0006\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 34,loss = 0.0007\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 34,loss = 0.0013\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  34\n",
            "i= 0\n",
            "iteration 0, epochs 35,loss = 0.0009\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 35,loss = 0.0012\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 35,loss = 0.0021\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 35,loss = 0.0011\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 35,loss = 0.0015\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.02% epoch is  35\n",
            "i= 0\n",
            "iteration 0, epochs 36,loss = 0.0004\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 36,loss = 0.0004\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 36,loss = 0.0003\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 36,loss = 0.0002\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 36,loss = 0.0003\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 49.02% epoch is  36\n",
            "i= 0\n",
            "iteration 0, epochs 37,loss = 0.0005\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 37,loss = 0.0010\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 37,loss = 0.0012\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 37,loss = 0.0015\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 37,loss = 0.0007\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  37\n",
            "i= 0\n",
            "iteration 0, epochs 38,loss = 0.0012\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 38,loss = 0.0013\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 38,loss = 0.0007\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 38,loss = 0.0010\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 38,loss = 0.0010\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  38\n",
            "i= 0\n",
            "iteration 0, epochs 39,loss = 0.0009\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 39,loss = 0.0006\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 39,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 39,loss = 0.0007\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 39,loss = 0.0016\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  39\n",
            "i= 0\n",
            "iteration 0, epochs 40,loss = 0.0007\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 40,loss = 0.0012\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 40,loss = 0.0005\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 40,loss = 0.0011\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 40,loss = 0.0009\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  40\n",
            "i= 0\n",
            "iteration 0, epochs 41,loss = 0.0005\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 41,loss = 0.0007\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 41,loss = 0.0004\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 41,loss = 0.0003\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 41,loss = 0.0003\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  41\n",
            "i= 0\n",
            "iteration 0, epochs 42,loss = 0.0006\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 42,loss = 0.0006\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 42,loss = 0.0006\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 42,loss = 0.0005\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 42,loss = 0.0004\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  42\n",
            "i= 0\n",
            "iteration 0, epochs 43,loss = 0.0002\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 43,loss = 0.0003\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 43,loss = 0.0003\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 43,loss = 0.0006\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 43,loss = 0.0089\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  43\n",
            "i= 0\n",
            "iteration 0, epochs 44,loss = 0.0007\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 44,loss = 0.0006\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 44,loss = 0.0005\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 44,loss = 0.0003\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 44,loss = 0.0003\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  44\n",
            "i= 0\n",
            "iteration 0, epochs 45,loss = 0.0005\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 45,loss = 0.0008\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 45,loss = 0.0002\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 45,loss = 0.0004\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 45,loss = 0.0002\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  45\n",
            "i= 0\n",
            "iteration 0, epochs 46,loss = 0.0004\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 46,loss = 0.0009\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 46,loss = 0.0008\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 46,loss = 0.0004\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 46,loss = 0.0004\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  46\n",
            "i= 0\n",
            "iteration 0, epochs 47,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 47,loss = 0.0003\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 47,loss = 0.0003\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 47,loss = 0.0004\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 47,loss = 0.0002\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  47\n",
            "i= 0\n",
            "iteration 0, epochs 48,loss = 0.0003\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 48,loss = 0.0003\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 48,loss = 0.0003\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 48,loss = 0.0003\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 48,loss = 0.0004\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  48\n",
            "i= 0\n",
            "iteration 0, epochs 49,loss = 0.0002\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 49,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 49,loss = 0.0049\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 49,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 49,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  49\n",
            "i= 0\n",
            "iteration 0, epochs 50,loss = 0.0002\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 50,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 50,loss = 0.0002\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 50,loss = 0.0002\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 50,loss = 0.0003\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  50\n",
            "i= 0\n",
            "iteration 0, epochs 51,loss = 0.0003\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 51,loss = 0.0002\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 51,loss = 0.0002\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 51,loss = 0.0002\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 51,loss = 0.0005\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  51\n",
            "i= 0\n",
            "iteration 0, epochs 52,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 52,loss = 0.0003\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 52,loss = 0.0003\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 52,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 52,loss = 0.0003\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  52\n",
            "i= 0\n",
            "iteration 0, epochs 53,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 53,loss = 0.0003\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 53,loss = 0.0002\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 53,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 53,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  53\n",
            "i= 0\n",
            "iteration 0, epochs 54,loss = 0.0002\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 54,loss = 0.0002\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 54,loss = 0.0016\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 54,loss = 0.0003\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 54,loss = 0.0002\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  54\n",
            "i= 0\n",
            "iteration 0, epochs 55,loss = 0.0017\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 55,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 55,loss = 0.0002\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 55,loss = 0.0002\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 55,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.84% epoch is  55\n",
            "i= 0\n",
            "iteration 0, epochs 56,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 56,loss = 0.0032\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 56,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 56,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 56,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  56\n",
            "i= 0\n",
            "iteration 0, epochs 57,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 57,loss = 0.0002\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 57,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 57,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 57,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.45% epoch is  57\n",
            "i= 0\n",
            "iteration 0, epochs 58,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 58,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 58,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 58,loss = 0.0031\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 58,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  58\n",
            "i= 0\n",
            "iteration 0, epochs 59,loss = 0.0002\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 59,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 59,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 59,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 59,loss = 0.0002\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  59\n",
            "i= 0\n",
            "iteration 0, epochs 60,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 60,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 60,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 60,loss = 0.0002\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 60,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  60\n",
            "i= 0\n",
            "iteration 0, epochs 61,loss = 0.0002\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 61,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 61,loss = 0.0018\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 61,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 61,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  61\n",
            "i= 0\n",
            "iteration 0, epochs 62,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 62,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 62,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 62,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 62,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  62\n",
            "i= 0\n",
            "iteration 0, epochs 63,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 63,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 63,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 63,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 63,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  63\n",
            "i= 0\n",
            "iteration 0, epochs 64,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 64,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 64,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 64,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 64,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  64\n",
            "i= 0\n",
            "iteration 0, epochs 65,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 65,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 65,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 65,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 65,loss = 0.0017\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  65\n",
            "i= 0\n",
            "iteration 0, epochs 66,loss = 0.0013\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 66,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 66,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 66,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 66,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  66\n",
            "i= 0\n",
            "iteration 0, epochs 67,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 67,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 67,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 67,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 67,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  67\n",
            "i= 0\n",
            "iteration 0, epochs 68,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 68,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 68,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 68,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 68,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  68\n",
            "i= 0\n",
            "iteration 0, epochs 69,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 69,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 69,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 69,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 69,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  69\n",
            "i= 0\n",
            "iteration 0, epochs 70,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 70,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 70,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 70,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 70,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  70\n",
            "i= 0\n",
            "iteration 0, epochs 71,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 71,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 71,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 71,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 71,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  71\n",
            "i= 0\n",
            "iteration 0, epochs 72,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 72,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 72,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 72,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 72,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  72\n",
            "i= 0\n",
            "iteration 0, epochs 73,loss = 0.0008\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 73,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 73,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 73,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 73,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  73\n",
            "i= 0\n",
            "iteration 0, epochs 74,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 74,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 74,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 74,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 74,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  74\n",
            "i= 0\n",
            "iteration 0, epochs 75,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 75,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 75,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 75,loss = 0.0007\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 75,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 46.67% epoch is  75\n",
            "i= 0\n",
            "iteration 0, epochs 76,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 76,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 76,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 76,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 76,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  76\n",
            "i= 0\n",
            "iteration 0, epochs 77,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 77,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 77,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 77,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 77,loss = 0.0007\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  77\n",
            "i= 0\n",
            "iteration 0, epochs 78,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 78,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 78,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 78,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 78,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  78\n",
            "i= 0\n",
            "iteration 0, epochs 79,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 79,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 79,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 79,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 79,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  79\n",
            "i= 0\n",
            "iteration 0, epochs 80,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 80,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 80,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 80,loss = 0.0001\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 80,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  80\n",
            "i= 0\n",
            "iteration 0, epochs 81,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 81,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 81,loss = 0.0001\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 81,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 81,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  81\n",
            "i= 0\n",
            "iteration 0, epochs 82,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 82,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 82,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 82,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 82,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  82\n",
            "i= 0\n",
            "iteration 0, epochs 83,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 83,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 83,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 83,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 83,loss = 0.0007\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  83\n",
            "i= 0\n",
            "iteration 0, epochs 84,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 84,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 84,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 84,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 84,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  84\n",
            "i= 0\n",
            "iteration 0, epochs 85,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 85,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 85,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 85,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 85,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  85\n",
            "i= 0\n",
            "iteration 0, epochs 86,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 86,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 86,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 86,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 86,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  86\n",
            "i= 0\n",
            "iteration 0, epochs 87,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 87,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 87,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 87,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 87,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  87\n",
            "i= 0\n",
            "iteration 0, epochs 88,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 88,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 88,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 88,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 88,loss = 0.0001\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  88\n",
            "i= 0\n",
            "iteration 0, epochs 89,loss = 0.0001\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 89,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 89,loss = 0.0005\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 89,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 89,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  89\n",
            "i= 0\n",
            "iteration 0, epochs 90,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 90,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 90,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 90,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 90,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  90\n",
            "i= 0\n",
            "iteration 0, epochs 91,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 91,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 91,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 91,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 91,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  91\n",
            "i= 0\n",
            "iteration 0, epochs 92,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 92,loss = 0.0001\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 92,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 92,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 92,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  92\n",
            "i= 0\n",
            "iteration 0, epochs 93,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 93,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 93,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 93,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 93,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  93\n",
            "i= 0\n",
            "iteration 0, epochs 94,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 94,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 94,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 94,loss = 0.0005\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 94,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  94\n",
            "i= 0\n",
            "iteration 0, epochs 95,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 95,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 95,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 95,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 95,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  95\n",
            "i= 0\n",
            "iteration 0, epochs 96,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 96,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 96,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 96,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 96,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  96\n",
            "i= 0\n",
            "iteration 0, epochs 97,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 97,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 97,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 97,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 97,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  97\n",
            "i= 0\n",
            "iteration 0, epochs 98,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 98,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 98,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 98,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 98,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  98\n",
            "i= 0\n",
            "iteration 0, epochs 99,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 99,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 99,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 99,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 99,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  99\n",
            "i= 0\n",
            "iteration 0, epochs 100,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 100,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 100,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 100,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 100,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  100\n",
            "i= 0\n",
            "iteration 0, epochs 101,loss = 0.0000\n",
            "i= 1\n",
            "i= 2\n",
            "i= 3\n",
            "i= 4\n",
            "i= 5\n",
            "iteration 5, epochs 101,loss = 0.0000\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "iteration 10, epochs 101,loss = 0.0000\n",
            "i= 11\n",
            "i= 12\n",
            "i= 13\n",
            "i= 14\n",
            "i= 15\n",
            "iteration 15, epochs 101,loss = 0.0000\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 19\n",
            "i= 20\n",
            "iteration 20, epochs 101,loss = 0.0000\n",
            "i= 21\n",
            "i= 22\n",
            "i= 23\n",
            "accuracy is 47.06% epoch is  101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1N-pmGOY_QT",
        "outputId": "c1f12261-d366-47fd-fec6-ab7f81a9cbcb"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.47058823529411764"
            ]
          },
          "execution_count": 84,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS0ogSiAxlXN",
        "outputId": "2af98b07-9a17-4328-9f7e-f2d85f88d33e"
      },
      "source": [
        "for i, (x_batch,y_batch) in enumerate(train_dl):\n",
        "    #x_batch = torch.tensor(x_batch).flatten()\n",
        "    print(\"i=\", i)\n",
        "    model.train()\n",
        "    x_batch = x_batch.unsqueeze(1)\n",
        "    print(\"x_batch size\",x_batch.size())\n",
        "    optimizer.zero_grad()\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model(x_batch)\n",
        "    print(out.size())\n",
        "    print(y_batch.size())\n",
        "    loss = criteria(out,y_batch)\n",
        "    print(\"loss\",loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 5 == 0:\n",
        "      print(\"iteration %d, loss = %.4f\" %(i,loss.item()))\n",
        "    #writer.add_scalars('Training vs validation Loss',{'Training' : loss},1 *len(train_dl)+i)\n",
        "    \n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i= 0\n",
            "x_batch size torch.Size([32, 1, 4000])\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output_cnn tensor([[[-0.6327, -0.6333, -0.6338,  ..., -0.6301, -0.6318, -0.6331]],\n",
            "\n",
            "        [[-0.6492, -0.6489, -0.6481,  ..., -0.6364, -0.6334, -0.6260]],\n",
            "\n",
            "        [[-0.6092, -0.6108, -0.6125,  ..., -0.6303, -0.6301, -0.6298]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.6226, -0.6224, -0.6224,  ..., -0.6381, -0.6397, -0.6419]],\n",
            "\n",
            "        [[-0.6313, -0.6316, -0.6317,  ..., -0.6298, -0.6294, -0.6296]],\n",
            "\n",
            "        [[-0.6183, -0.6186, -0.6184,  ..., -0.6402, -0.6398, -0.6393]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "output_cnn_size torch.Size([32, 1, 4000])\n",
            "out_size fc_cnn torch.Size([32, 1, 100])\n",
            "ho,co size torch.Size([1, 32, 4000]) torch.Size([1, 32, 4000])\n",
            "output shape lstm torch.Size([32, 1, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "final output tensor([[ 0.0053,  0.0145, -0.0059],\n",
            "        [ 0.0052,  0.0146, -0.0057],\n",
            "        [ 0.0054,  0.0145, -0.0061],\n",
            "        [ 0.0056,  0.0146, -0.0057],\n",
            "        [ 0.0054,  0.0147, -0.0060],\n",
            "        [ 0.0062,  0.0143, -0.0062],\n",
            "        [ 0.0053,  0.0143, -0.0058],\n",
            "        [ 0.0051,  0.0156, -0.0056],\n",
            "        [ 0.0055,  0.0144, -0.0059],\n",
            "        [ 0.0055,  0.0143, -0.0061],\n",
            "        [ 0.0056,  0.0144, -0.0058],\n",
            "        [ 0.0045,  0.0152, -0.0053],\n",
            "        [ 0.0055,  0.0145, -0.0059],\n",
            "        [ 0.0057,  0.0144, -0.0057],\n",
            "        [ 0.0054,  0.0145, -0.0059],\n",
            "        [ 0.0055,  0.0145, -0.0057],\n",
            "        [ 0.0057,  0.0145, -0.0060],\n",
            "        [ 0.0059,  0.0133, -0.0063],\n",
            "        [ 0.0056,  0.0145, -0.0059],\n",
            "        [ 0.0054,  0.0147, -0.0059],\n",
            "        [ 0.0055,  0.0145, -0.0060],\n",
            "        [ 0.0050,  0.0145, -0.0061],\n",
            "        [ 0.0053,  0.0147, -0.0057],\n",
            "        [ 0.0050,  0.0146, -0.0064],\n",
            "        [ 0.0052,  0.0146, -0.0058],\n",
            "        [ 0.0055,  0.0144, -0.0059],\n",
            "        [ 0.0055,  0.0142, -0.0060],\n",
            "        [ 0.0068,  0.0148, -0.0063],\n",
            "        [ 0.0056,  0.0146, -0.0060],\n",
            "        [ 0.0054,  0.0144, -0.0059],\n",
            "        [ 0.0057,  0.0147, -0.0064],\n",
            "        [ 0.0056,  0.0145, -0.0059]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32])\n",
            "loss tensor(1.0984, grad_fn=<NllLossBackward>)\n",
            "iteration 0, loss = 1.0984\n",
            "i= 1\n",
            "x_batch size torch.Size([32, 1, 4000])\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output_cnn tensor([[[-0.6123, -0.6170, -0.6221,  ..., -0.6228, -0.6242, -0.6256]],\n",
            "\n",
            "        [[-0.7161, -0.6918, -0.6628,  ..., -0.5119, -0.5101, -0.5041]],\n",
            "\n",
            "        [[-0.6135, -0.6131, -0.6127,  ..., -0.6225, -0.6222, -0.6220]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.6167, -0.6153, -0.6154,  ..., -0.6437, -0.6421, -0.6405]],\n",
            "\n",
            "        [[-0.6317, -0.6324, -0.6327,  ..., -0.6392, -0.6400, -0.6405]],\n",
            "\n",
            "        [[-0.6402, -0.6400, -0.6396,  ..., -0.6344, -0.6346, -0.6345]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "output_cnn_size torch.Size([32, 1, 4000])\n",
            "out_size fc_cnn torch.Size([32, 1, 100])\n",
            "ho,co size torch.Size([1, 32, 4000]) torch.Size([1, 32, 4000])\n",
            "output shape lstm torch.Size([32, 1, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "final output tensor([[-0.5538,  0.4143,  0.2395],\n",
            "        [-0.5470,  0.4115,  0.2350],\n",
            "        [-0.5558,  0.4153,  0.2408],\n",
            "        [-0.5546,  0.4149,  0.2400],\n",
            "        [-0.5556,  0.4157,  0.2401],\n",
            "        [-0.5577,  0.4170,  0.2413],\n",
            "        [-0.5577,  0.4162,  0.2422],\n",
            "        [-0.5534,  0.4146,  0.2395],\n",
            "        [-0.5552,  0.4165,  0.2389],\n",
            "        [-0.5555,  0.4164,  0.2399],\n",
            "        [-0.5556,  0.4164,  0.2399],\n",
            "        [-0.5565,  0.4158,  0.2407],\n",
            "        [-0.5547,  0.4151,  0.2401],\n",
            "        [-0.5557,  0.4154,  0.2407],\n",
            "        [-0.5547,  0.4155,  0.2402],\n",
            "        [-0.5578,  0.4169,  0.2417],\n",
            "        [-0.5537,  0.4145,  0.2396],\n",
            "        [-0.5546,  0.4149,  0.2399],\n",
            "        [-0.5579,  0.4165,  0.2418],\n",
            "        [-0.5558,  0.4159,  0.2404],\n",
            "        [-0.5561,  0.4159,  0.2404],\n",
            "        [-0.5566,  0.4161,  0.2409],\n",
            "        [-0.5548,  0.4152,  0.2401],\n",
            "        [-0.5552,  0.4154,  0.2401],\n",
            "        [-0.5513,  0.4131,  0.2377],\n",
            "        [-0.5555,  0.4159,  0.2402],\n",
            "        [-0.5552,  0.4152,  0.2404],\n",
            "        [-0.5575,  0.4179,  0.2404],\n",
            "        [-0.5571,  0.4166,  0.2407],\n",
            "        [-0.5549,  0.4151,  0.2403],\n",
            "        [-0.5547,  0.4148,  0.2400],\n",
            "        [-0.5550,  0.4151,  0.2404]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32])\n",
            "loss tensor(1.1155, grad_fn=<NllLossBackward>)\n",
            "i= 2\n",
            "x_batch size torch.Size([32, 1, 4000])\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output_cnn tensor([[[-0.6132, -0.6121, -0.6113,  ..., -0.6409, -0.6409, -0.6409]],\n",
            "\n",
            "        [[-0.3182, -0.2738, -0.2586,  ..., -0.6211, -0.6220, -0.6231]],\n",
            "\n",
            "        [[-0.6243, -0.6248, -0.6253,  ..., -0.6463, -0.6729, -0.6978]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.5807, -0.5795, -0.5787,  ..., -0.6488, -0.6498, -0.6421]],\n",
            "\n",
            "        [[-0.6195, -0.6180, -0.6171,  ..., -0.6229, -0.6234, -0.6241]],\n",
            "\n",
            "        [[-0.7210, -0.7039, -0.6804,  ..., -0.6321, -0.6326, -0.6327]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "output_cnn_size torch.Size([32, 1, 4000])\n",
            "out_size fc_cnn torch.Size([32, 1, 100])\n",
            "ho,co size torch.Size([1, 32, 4000]) torch.Size([1, 32, 4000])\n",
            "output shape lstm torch.Size([32, 1, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "final output tensor([[ 1.1645, -1.6359,  0.4027],\n",
            "        [ 1.1591, -1.6293,  0.4017],\n",
            "        [ 1.1568, -1.6321,  0.4057],\n",
            "        [ 1.1649, -1.6335,  0.4014],\n",
            "        [ 1.1637, -1.6335,  0.4014],\n",
            "        [ 1.1635, -1.6334,  0.4019],\n",
            "        [ 1.1637, -1.6333,  0.4019],\n",
            "        [ 1.1629, -1.6337,  0.4026],\n",
            "        [ 1.1638, -1.6338,  0.4021],\n",
            "        [ 1.1638, -1.6331,  0.4010],\n",
            "        [ 1.1633, -1.6332,  0.4020],\n",
            "        [ 1.1641, -1.6341,  0.4024],\n",
            "        [ 1.1637, -1.6346,  0.4027],\n",
            "        [ 1.1628, -1.6334,  0.4020],\n",
            "        [ 1.1636, -1.6323,  0.4012],\n",
            "        [ 1.1617, -1.6340,  0.4039],\n",
            "        [ 1.1642, -1.6334,  0.4015],\n",
            "        [ 1.1639, -1.6326,  0.4007],\n",
            "        [ 1.1642, -1.6341,  0.4020],\n",
            "        [ 1.1632, -1.6321,  0.4006],\n",
            "        [ 1.1649, -1.6361,  0.4028],\n",
            "        [ 1.1635, -1.6331,  0.4018],\n",
            "        [ 1.1639, -1.6334,  0.4016],\n",
            "        [ 1.1634, -1.6334,  0.4021],\n",
            "        [ 1.1669, -1.6333,  0.3982],\n",
            "        [ 1.1646, -1.6335,  0.4013],\n",
            "        [ 1.1624, -1.6329,  0.4026],\n",
            "        [ 1.1639, -1.6341,  0.4023],\n",
            "        [ 1.1612, -1.6307,  0.4015],\n",
            "        [ 1.1635, -1.6334,  0.4019],\n",
            "        [ 1.1632, -1.6331,  0.4018],\n",
            "        [ 1.1631, -1.6332,  0.4023]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32])\n",
            "loss tensor(1.2262, grad_fn=<NllLossBackward>)\n",
            "i= 3\n",
            "x_batch size torch.Size([32, 1, 4000])\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output_cnn tensor([[[-0.6455, -0.6533, -0.6547,  ..., -0.6287, -0.6292, -0.6327]],\n",
            "\n",
            "        [[-0.6236, -0.6235, -0.6239,  ..., -0.6279, -0.6286, -0.6293]],\n",
            "\n",
            "        [[-0.6307, -0.6298, -0.6291,  ..., -0.6334, -0.6326, -0.6319]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.3886, -0.3935, -0.3969,  ..., -0.6300, -0.6290, -0.6283]],\n",
            "\n",
            "        [[-0.6180, -0.6184, -0.6186,  ..., -0.6045, -0.6060, -0.6053]],\n",
            "\n",
            "        [[-0.6294, -0.6285, -0.6276,  ..., -0.6099, -0.6169, -0.6243]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "output_cnn_size torch.Size([32, 1, 4000])\n",
            "out_size fc_cnn torch.Size([32, 1, 100])\n",
            "ho,co size torch.Size([1, 32, 4000]) torch.Size([1, 32, 4000])\n",
            "output shape lstm torch.Size([32, 1, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "final output tensor([[ 0.8611, -0.6645, -0.2398],\n",
            "        [ 0.8600, -0.6639, -0.2392],\n",
            "        [ 0.8595, -0.6630, -0.2396],\n",
            "        [ 0.8609, -0.6644, -0.2397],\n",
            "        [ 0.8608, -0.6636, -0.2402],\n",
            "        [ 0.8574, -0.6678, -0.2350],\n",
            "        [ 0.8612, -0.6652, -0.2394],\n",
            "        [ 0.8673, -0.6656, -0.2451],\n",
            "        [ 0.8609, -0.6649, -0.2393],\n",
            "        [ 0.8610, -0.6639, -0.2401],\n",
            "        [ 0.8593, -0.6637, -0.2389],\n",
            "        [ 0.8599, -0.6641, -0.2391],\n",
            "        [ 0.8605, -0.6636, -0.2398],\n",
            "        [ 0.8606, -0.6640, -0.2396],\n",
            "        [ 0.8605, -0.6638, -0.2396],\n",
            "        [ 0.8601, -0.6641, -0.2392],\n",
            "        [ 0.8606, -0.6648, -0.2392],\n",
            "        [ 0.8602, -0.6647, -0.2386],\n",
            "        [ 0.8606, -0.6618, -0.2409],\n",
            "        [ 0.8610, -0.6633, -0.2409],\n",
            "        [ 0.8610, -0.6629, -0.2406],\n",
            "        [ 0.8612, -0.6641, -0.2407],\n",
            "        [ 0.8617, -0.6640, -0.2404],\n",
            "        [ 0.8596, -0.6637, -0.2393],\n",
            "        [ 0.8594, -0.6656, -0.2362],\n",
            "        [ 0.8600, -0.6636, -0.2395],\n",
            "        [ 0.8601, -0.6638, -0.2396],\n",
            "        [ 0.8612, -0.6635, -0.2404],\n",
            "        [ 0.8601, -0.6643, -0.2390],\n",
            "        [ 0.8605, -0.6621, -0.2402],\n",
            "        [ 0.8606, -0.6655, -0.2378],\n",
            "        [ 0.8612, -0.6635, -0.2402]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32])\n",
            "loss tensor(1.0550, grad_fn=<NllLossBackward>)\n",
            "i= 4\n",
            "x_batch size torch.Size([32, 1, 4000])\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output_cnn tensor([[[-0.6233, -0.6240, -0.6247,  ..., -0.6139, -0.6161, -0.6203]],\n",
            "\n",
            "        [[-0.6367, -0.6369, -0.6384,  ..., -0.6366, -0.6374, -0.6368]],\n",
            "\n",
            "        [[-0.6386, -0.6359, -0.6328,  ..., -0.6422, -0.6488, -0.6625]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.6441, -0.6397, -0.6357,  ..., -0.6085, -0.6152, -0.6220]],\n",
            "\n",
            "        [[-0.6300, -0.6297, -0.6293,  ..., -0.6203, -0.6190, -0.6180]],\n",
            "\n",
            "        [[-0.6673, -0.6960, -0.7237,  ..., -0.6065, -0.6063, -0.6061]]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "output_cnn_size torch.Size([32, 1, 4000])\n",
            "out_size fc_cnn torch.Size([32, 1, 100])\n",
            "ho,co size torch.Size([1, 32, 4000]) torch.Size([1, 32, 4000])\n",
            "output shape lstm torch.Size([32, 1, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "final output tensor([[ 0.1500, -0.2964,  0.1432],\n",
            "        [ 0.1491, -0.2969,  0.1445],\n",
            "        [ 0.1493, -0.2975,  0.1443],\n",
            "        [ 0.1489, -0.2978,  0.1452],\n",
            "        [ 0.1464, -0.3000,  0.1484],\n",
            "        [ 0.1500, -0.2967,  0.1436],\n",
            "        [ 0.1493, -0.2972,  0.1442],\n",
            "        [ 0.1493, -0.2971,  0.1446],\n",
            "        [ 0.1500, -0.2964,  0.1437],\n",
            "        [ 0.1492, -0.2970,  0.1444],\n",
            "        [ 0.1493, -0.2975,  0.1445],\n",
            "        [ 0.1494, -0.2965,  0.1440],\n",
            "        [ 0.1493, -0.2978,  0.1448],\n",
            "        [ 0.1503, -0.2966,  0.1434],\n",
            "        [ 0.1491, -0.2972,  0.1445],\n",
            "        [ 0.1493, -0.2969,  0.1439],\n",
            "        [ 0.1481, -0.2974,  0.1448],\n",
            "        [ 0.1504, -0.2959,  0.1428],\n",
            "        [ 0.1493, -0.2969,  0.1444],\n",
            "        [ 0.1495, -0.2962,  0.1441],\n",
            "        [ 0.1491, -0.2971,  0.1441],\n",
            "        [ 0.1496, -0.2973,  0.1443],\n",
            "        [ 0.1496, -0.2972,  0.1443],\n",
            "        [ 0.1517, -0.2927,  0.1400],\n",
            "        [ 0.1493, -0.2958,  0.1436],\n",
            "        [ 0.1496, -0.2972,  0.1445],\n",
            "        [ 0.1496, -0.2955,  0.1431],\n",
            "        [ 0.1514, -0.2944,  0.1418],\n",
            "        [ 0.1505, -0.2963,  0.1424],\n",
            "        [ 0.1491, -0.2969,  0.1442],\n",
            "        [ 0.1499, -0.2964,  0.1434],\n",
            "        [ 0.1503, -0.2962,  0.1431]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32])\n",
            "loss tensor(1.0683, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM0OhJceBIF_",
        "outputId": "5822736a-084d-4e09-c3c8-582b313a17fa"
      },
      "source": [
        "total = 0.0\n",
        "correct = 0.0\n",
        "for x_val,y_val in valid_dl:\n",
        "   model.eval()\n",
        "   #x_val, y_val = [t for t in (x_val, y_val)]\n",
        "   #print(x_val)\n",
        "   x_val =x_val.unsqueeze(1)\n",
        "   #print(\"X_val size\", x_val.size())\n",
        "   optimizer.zero_grad()\n",
        "   x_val = x_val.to(device)\n",
        "   y_val = y_val.to(device)\n",
        "   #print(\"x_val\",x_val.size())\n",
        "   out = model(x_val)\n",
        "   y_val = torch.unsqueeze(y_val,0)\n",
        "   print(\"y_val\", y_val)\n",
        "   print(\"y_val\",y_val.size())\n",
        "   preds = F.log_softmax(out, dim=1).argmax(dim = 1)\n",
        "   print(\"predictions\", preds)\n",
        "   print(\"y_val size(0)\", y_val.size(0))\n",
        "   total = total + y_val.size(1)\n",
        "   correct += (preds == y_val).sum().item()\n",
        "   print(\"total is =\",total)\n",
        "   print(\"number of correct values are =\", correct)\n",
        "   acc = correct/total\n",
        "   print(f'accuracy is {acc:2.2%}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[0, 0, 0, 2, 2, 2, 0, 2, 2, 1, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2,\n",
            "         1, 0, 2, 0, 1, 1, 1, 2]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 32.0\n",
            "number of correct values are = 15.0\n",
            "accuracy is 46.88%\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 2, 2, 0, 0, 0, 2, 1,\n",
            "         0, 2, 1, 2, 1, 0, 2, 0]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 64.0\n",
            "number of correct values are = 28.0\n",
            "accuracy is 43.75%\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[2, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 2, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 1, 2,\n",
            "         0, 2, 2, 2, 2, 2, 0, 1]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 96.0\n",
            "number of correct values are = 40.0\n",
            "accuracy is 41.67%\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[0, 1, 0, 0, 1, 0, 2, 1, 1, 0, 0, 0, 1, 0, 2, 1, 2, 0, 2, 2, 0, 1, 1, 0,\n",
            "         0, 2, 1, 1, 2, 0, 1, 2]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 128.0\n",
            "number of correct values are = 53.0\n",
            "accuracy is 41.41%\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0, 2, 0, 0, 2, 2, 2, 2, 1,\n",
            "         0, 2, 1, 0, 0, 0, 1, 0]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 160.0\n",
            "number of correct values are = 65.0\n",
            "accuracy is 40.62%\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[2, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 2, 0, 2,\n",
            "         0, 0, 0, 1, 1, 1, 1, 2]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 192.0\n",
            "number of correct values are = 76.0\n",
            "accuracy is 39.58%\n",
            "h0 size in init function torch.Size([1, 32, 4000])\n",
            "output size fc_lstm torch.Size([32, 3])\n",
            "y_val tensor([[1, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2,\n",
            "         2, 2, 0, 0, 0, 2, 1, 2]])\n",
            "y_val torch.Size([1, 32])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 224.0\n",
            "number of correct values are = 91.0\n",
            "accuracy is 40.62%\n",
            "h0 size in init function torch.Size([1, 31, 4000])\n",
            "output size fc_lstm torch.Size([31, 3])\n",
            "y_val tensor([[2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 1, 0, 0, 1,\n",
            "         1, 0, 1, 1, 2, 0, 0]])\n",
            "y_val torch.Size([1, 31])\n",
            "predictions tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0])\n",
            "y_val size(0) 1\n",
            "total is = 255.0\n",
            "number of correct values are = 100.0\n",
            "accuracy is 39.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RA2nZNowiwg"
      },
      "source": [
        "writer = SummaryWriter('runs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCRJm_-jxnL3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}